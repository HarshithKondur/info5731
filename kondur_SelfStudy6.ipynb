{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/kondurharshith/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192427"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emma = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "len(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emma = gutenberg.words('austen-emma.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/kondurharshith/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    400\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                             \u001b[0;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/collections.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mpieces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0melt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m             \u001b[0mpieces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mlength\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpieces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/reader/util.py\u001b[0m in \u001b[0;36miterate_from\u001b[0;34m(self, start_tok)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_toknum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoknum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_blocknum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             assert isinstance(tokens, (tuple, list, AbstractLazySequence)), (\n\u001b[1;32m    308\u001b[0m                 \u001b[0;34m'block reader %s() should return list or tuple.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/reader/plaintext.py\u001b[0m in \u001b[0;36m_read_sent_block\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 [\n\u001b[1;32m    142\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sent_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpara\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m                 ]\n\u001b[1;32m    145\u001b[0m             )\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m         \u001b[0mresource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m         \u001b[0;31m# This is where the magic happens!  Transform ourselves into\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0;31m# the object by modifying our own __dict__ and __class__ to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/kondurharshith/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "macbeth_sentences = gutenberg.sents('shakespeare-macbeth.txt')\n",
    "macbeth_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwebtext\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('webtext')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/webtext\u001b[0m\n\n  Searched in:\n    - '/Users/kondurharshith/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwebtext\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('webtext')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/webtext.zip/webtext/\u001b[0m\n\n  Searched in:\n    - '/Users/kondurharshith/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1a759aab48c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwebtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfileid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwebtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m      \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwebtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m65\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwebtext\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('webtext')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/webtext\u001b[0m\n\n  Searched in:\n    - '/Users/kondurharshith/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import webtext\n",
    "for fileid in webtext.fileids():\n",
    "     print(fileid, webtext.raw(fileid)[:65], '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mnps_chat\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('nps_chat')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/nps_chat\u001b[0m\n\n  Searched in:\n    - '/Users/kondurharshith/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mnps_chat\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('nps_chat')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/nps_chat.zip/nps_chat/\u001b[0m\n\n  Searched in:\n    - '/Users/kondurharshith/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fef6e6a3bf3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnps_chat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mchatroom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnps_chat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'10-19-20s_706posts.xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mchatroom\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mnps_chat\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('nps_chat')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/nps_chat\u001b[0m\n\n  Searched in:\n    - '/Users/kondurharshith/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import nps_chat\n",
    "chatroom = nps_chat.posts('10-19-20s_706posts.xml')\n",
    "chatroom[123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/kondurharshith/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " brown.words(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Does', 'our', 'society', 'have', 'a', 'runaway', ',', ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words(fileids=['cg22'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " brown.sents(categories=['news', 'editorial', 'reviews'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can: 94 could: 87 may: 93 might: 38 must: 53 will: 389 "
     ]
    }
   ],
   "source": [
    " from nltk.corpus import brown\n",
    " news_text = brown.words(categories='news')\n",
    " fdist = nltk.FreqDist(w.lower() for w in news_text)\n",
    " modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    " for m in modals:\n",
    "     print(m + ':', fdist[m], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-19-512a13a99ea8>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-512a13a99ea8>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist(\n",
    "           (genre, word)\n",
    "           for genre in brown.categories()\n",
    "           for word in brown.words(categories=genre))\n",
    " genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
    " modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    " cfd.tabulate(conditions=genres, samples=modals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-21-fab38ab8d5bd>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-fab38ab8d5bd>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    reuters.fileids()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import reuters\n",
    "   reuters.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reuters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-42fea72239c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreuters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'reuters' is not defined"
     ]
    }
   ],
   "source": [
    "reuters.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package inaugural to\n",
      "[nltk_data]     /Users/kondurharshith/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/inaugural.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('inaugural')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-Washington.txt',\n",
       " '1793-Washington.txt',\n",
       " '1797-Adams.txt',\n",
       " '1801-Jefferson.txt',\n",
       " '1805-Jefferson.txt',\n",
       " '1809-Madison.txt',\n",
       " '1813-Madison.txt',\n",
       " '1817-Monroe.txt',\n",
       " '1821-Monroe.txt',\n",
       " '1825-Adams.txt',\n",
       " '1829-Jackson.txt',\n",
       " '1833-Jackson.txt',\n",
       " '1837-VanBuren.txt',\n",
       " '1841-Harrison.txt',\n",
       " '1845-Polk.txt',\n",
       " '1849-Taylor.txt',\n",
       " '1853-Pierce.txt',\n",
       " '1857-Buchanan.txt',\n",
       " '1861-Lincoln.txt',\n",
       " '1865-Lincoln.txt',\n",
       " '1869-Grant.txt',\n",
       " '1873-Grant.txt',\n",
       " '1877-Hayes.txt',\n",
       " '1881-Garfield.txt',\n",
       " '1885-Cleveland.txt',\n",
       " '1889-Harrison.txt',\n",
       " '1893-Cleveland.txt',\n",
       " '1897-McKinley.txt',\n",
       " '1901-McKinley.txt',\n",
       " '1905-Roosevelt.txt',\n",
       " '1909-Taft.txt',\n",
       " '1913-Wilson.txt',\n",
       " '1917-Wilson.txt',\n",
       " '1921-Harding.txt',\n",
       " '1925-Coolidge.txt',\n",
       " '1929-Hoover.txt',\n",
       " '1933-Roosevelt.txt',\n",
       " '1937-Roosevelt.txt',\n",
       " '1941-Roosevelt.txt',\n",
       " '1945-Roosevelt.txt',\n",
       " '1949-Truman.txt',\n",
       " '1953-Eisenhower.txt',\n",
       " '1957-Eisenhower.txt',\n",
       " '1961-Kennedy.txt',\n",
       " '1965-Johnson.txt',\n",
       " '1969-Nixon.txt',\n",
       " '1973-Nixon.txt',\n",
       " '1977-Carter.txt',\n",
       " '1981-Reagan.txt',\n",
       " '1985-Reagan.txt',\n",
       " '1989-Bush.txt',\n",
       " '1993-Clinton.txt',\n",
       " '1997-Clinton.txt',\n",
       " '2001-Bush.txt',\n",
       " '2005-Bush.txt',\n",
       " '2009-Obama.txt']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import inaugural\n",
    "inaugural.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789',\n",
       " '1793',\n",
       " '1797',\n",
       " '1801',\n",
       " '1805',\n",
       " '1809',\n",
       " '1813',\n",
       " '1817',\n",
       " '1821',\n",
       " '1825',\n",
       " '1829',\n",
       " '1833',\n",
       " '1837',\n",
       " '1841',\n",
       " '1845',\n",
       " '1849',\n",
       " '1853',\n",
       " '1857',\n",
       " '1861',\n",
       " '1865',\n",
       " '1869',\n",
       " '1873',\n",
       " '1877',\n",
       " '1881',\n",
       " '1885',\n",
       " '1889',\n",
       " '1893',\n",
       " '1897',\n",
       " '1901',\n",
       " '1905',\n",
       " '1909',\n",
       " '1913',\n",
       " '1917',\n",
       " '1921',\n",
       " '1925',\n",
       " '1929',\n",
       " '1933',\n",
       " '1937',\n",
       " '1941',\n",
       " '1945',\n",
       " '1949',\n",
       " '1953',\n",
       " '1957',\n",
       " '1961',\n",
       " '1965',\n",
       " '1969',\n",
       " '1973',\n",
       " '1977',\n",
       " '1981',\n",
       " '1985',\n",
       " '1989',\n",
       " '1993',\n",
       " '1997',\n",
       " '2001',\n",
       " '2005',\n",
       " '2009']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fileid[:4] for fileid in inaugural.fileids()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist(\n",
    "           (target, fileid[:4])\n",
    "           for fileid in inaugural.fileids()\n",
    "           for w in inaugural.words(fileid)\n",
    "           for target in ['america', 'citizen']\n",
    "           if w.lower().startswith(target)) [1]\n",
    "cfd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mcess_esp\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('cess_esp')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/cess_esp\u001b[0m\n\n  Searched in:\n    - '/Users/kondurharshith/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mcess_esp\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('cess_esp')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/cess_esp.zip/cess_esp/\u001b[0m\n\n  Searched in:\n    - '/Users/kondurharshith/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-f3c0a80e5090>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcess_esp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mcess_esp\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('cess_esp')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/cess_esp\u001b[0m\n\n  Searched in:\n    - '/Users/kondurharshith/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    " nltk.corpus.cess_esp.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...] \n",
    "pairs = [('news', 'The'), ('news', 'Fulton'), ('news', 'County'), ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-34-1207d26c4282>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-1207d26c4282>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    cfd = nltk.ConditionalFreqDist(\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " from nltk.corpus import brown\n",
    "    cfd = nltk.ConditionalFreqDist(\n",
    "           (genre, word)\n",
    "           for genre in brown.categories()\n",
    "           for word in brown.words(categories=genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-36-daf0c3a789d3>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-daf0c3a789d3>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    len(genre_word)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "genre_word = [(genre, word) \n",
    "               for genre in ['news', 'romance'] \n",
    "               for word in brown.words(categories=genre)] \n",
    " len(genre_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'genre_word' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-ab6996a3e067>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConditionalFreqDist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenre_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcfd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'genre_word' is not defined"
     ]
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist(genre_word)\n",
    "cfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-40-8c867d867d25>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-40-8c867d867d25>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    cfd = nltk.ConditionalFreqDist(\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " from nltk.corpus import inaugural\n",
    "      cfd = nltk.ConditionalFreqDist(\n",
    "           (target, fileid[:4]) \n",
    "           for fileid in inaugural.fileids()\n",
    "           for w in inaugural.words(fileid)\n",
    "           for target in ['america', 'citizen'] \n",
    "           if w.lower().startswith(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-3bb729ed2673>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m cfd.tabulate(conditions=['English', 'German_Deutsch'],\n\u001b[0;32m----> 2\u001b[0;31m               samples=range(10), cumulative=True)\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/probability.py\u001b[0m in \u001b[0;36mtabulate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# percents = [f * 100 for f in freqs]  only in ProbDist?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "cfd.tabulate(conditions=['English', 'German_Deutsch'],\n",
    "              samples=range(10), cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-43-771d4df61816>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-43-771d4df61816>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    list(nltk.bigrams(sent))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "sent = ['In', 'the', 'beginning', 'God', 'created', 'the', 'heaven',\n",
    "    'and', 'the', 'earth', '.']\n",
    " list(nltk.bigrams(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mgenesis\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('genesis')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/genesis\u001b[0m\n\n  Searched in:\n    - '/Users/kondurharshith/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mgenesis\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('genesis')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/genesis.zip/genesis/\u001b[0m\n\n  Searched in:\n    - '/Users/kondurharshith/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-3c62f60e0480>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenesis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english-kjv.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mbigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConditionalFreqDist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mgenesis\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('genesis')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/genesis\u001b[0m\n\n  Searched in:\n    - '/Users/kondurharshith/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "def generate_model(cfdist, word, num=15):\n",
    "    for i in range(num):\n",
    "        print(word, end=' ')\n",
    "        word = cfdist[word].max()\n",
    "\n",
    "text = nltk.corpus.genesis.words('english-kjv.txt')\n",
    "bigrams = nltk.bigrams(text)\n",
    "cfd = nltk.ConditionalFreqDist(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-45-9cb78311a3f1>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-45-9cb78311a3f1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Monty Python\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Monty Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "def lexical_diversity(text):\n",
    "     return len(text) / len(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(my_text_data):\n",
    "     word_count = len(my_text_data)\n",
    "     vocab_size = len(set(my_text_data))\n",
    "     diversity_score = vocab_size / word_count\n",
    "     return diversity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-51-ee4e599f1d71>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-51-ee4e599f1d71>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    plural('wish')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from text_proc import plural\n",
    "   plural('wish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unusual_words(text):\n",
    "    text_vocab = set(w.lower() for w in text if w.isalpha())\n",
    "    english_vocab = set(w.lower() for w in nltk.corpus.words.words())\n",
    "    unusual = text_vocab - english_vocab\n",
    "    return sorted(unusual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kondurharshith/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-57-9e457c13d01d>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-57-9e457c13d01d>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    stopwords.words('english')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "  stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    content_fraction(nltk.corpus.reuters.words())\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "def content_fraction(text):\n",
    "        stopwords = nltk.corpus.stopwords.words('english')\n",
    "        content = [w for w in text if w.lower() not in stopwords]\n",
    "        return len(content) / len(text)\n",
    " \n",
    "  content_fraction(nltk.corpus.reuters.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-66-26ec087430af>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-66-26ec087430af>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    obligatory = 'r'\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "puzzle_letters = nltk.FreqDist('egivrvonl')\n",
    " obligatory = 'r'\n",
    " wordlist = nltk.corpus.words.words()\n",
    " [w for w in wordlist if len(w) >= 6 [1]\n",
    "                      and obligatory in w [2]\n",
    "                      and nltk.FreqDist(w) <= puzzle_letters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mnames\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('names')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/names\u001b[0m\n\n  Searched in:\n    - '/Users/kondurharshith/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mnames\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('names')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/names.zip/names/\u001b[0m\n\n  Searched in:\n    - '/Users/kondurharshith/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-ff296eabed1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mnames\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('names')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/names\u001b[0m\n\n  Searched in:\n    - '/Users/kondurharshith/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "names = nltk.corpus.names\n",
    "names.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-69-2f94717d432a>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-69-2f94717d432a>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    cfd.plot()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist(\n",
    "            (fileid, name[-1])\n",
    "           for fileid in names.fileids()\n",
    "           for name in names.words(fileid))\n",
    " cfd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     /Users/kondurharshith/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/cmudict.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('cmudict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133737"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries = nltk.corpus.cmudict.entries()\n",
    "len(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import nltk, re, pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'urlopen' from 'urllib' (/anaconda3/lib/python3.7/urllib/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-b14202b5f73d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0murllib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"http://www.gutenberg.org/files/2554/2554.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'urlopen' from 'urllib' (/anaconda3/lib/python3.7/urllib/__init__.py)"
     ]
    }
   ],
   "source": [
    " from urllib import urlopen\n",
    " url = \"http://www.gutenberg.org/files/2554/2554.txt\"\n",
    " raw = urlopen(url).read()\n",
    " type(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-82-ad05822856d4>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-82-ad05822856d4>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    type(tokens)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(raw)\n",
    "   type(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-84-07e64268f0ec>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-84-07e64268f0ec>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    type(text)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " text = nltk.Text(tokens)\n",
    "    type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-86-51e8916b974e>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-86-51e8916b974e>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    html = urlopen(url).read()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "url = \"http://news.bbc.co.uk/2/hi/health/2284783.stm\"\n",
    " html = urlopen(url).read()\n",
    "    html[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'html' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-657a5594a53d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'html' is not defined"
     ]
    }
   ],
   "source": [
    "raw = nltk.clean_html(html)\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-89-38ee8e07719f>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-89-38ee8e07719f>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    text = nltk.Text(tokens)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "tokens = tokens[96:399]\n",
    " text = nltk.Text(tokens)\n",
    " text.concordance('gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-90-bba5d4f41c3c>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-90-bba5d4f41c3c>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    raw = f.read()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " f = open('document.txt')\n",
    "    raw = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-91-6ab6364e7248>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-91-6ab6364e7248>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    os.listdir('.')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    " os.listdir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-571e9fb02258>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-571e9fb02258>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-95-5e39e87d7919>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-95-5e39e87d7919>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    print line.strip()\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "f = open('document.txt', 'rU')\n",
    "for line in f:\n",
    "    print line.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: 'U' mode is deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "path = nltk.data.find('corpora/gutenberg/melville-moby_dick.txt')\n",
    "raw = open(path, 'rU').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u',\n",
       " 'e',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " 'e',\n",
       " 'i',\n",
       " 'a',\n",
       " 'i',\n",
       " 'o',\n",
       " 'i',\n",
       " 'o',\n",
       " 'u']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'supercalifragilisticexpialidocious'\n",
    "re.findall(r'[aeiou]', word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mtreebank\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('treebank')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/treebank/combined\u001b[0m\n\n  Searched in:\n    - '/Users/kondurharshith/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mtreebank\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('treebank')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/treebank.zip/treebank/combined/\u001b[0m\n\n  Searched in:\n    - '/Users/kondurharshith/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-0c093af86755>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwsj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtreebank\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m fd = nltk.FreqDist(vs for word in wsj\n\u001b[1;32m      3\u001b[0m                 for vs in re.findall(r'[aeiou]{2,}', word))\n\u001b[1;32m      4\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mtreebank\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('treebank')\n  \u001b[0m\n  Attempted to load \u001b[93mcorpora/treebank/combined\u001b[0m\n\n  Searched in:\n    - '/Users/kondurharshith/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "wsj = sorted(set(nltk.corpus.treebank.words()))\n",
    "fd = nltk.FreqDist(vs for word in wsj\n",
    "                for vs in re.findall(r'[aeiou]{2,}', word))\n",
    "fd.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-104-4cfa62615b66>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-104-4cfa62615b66>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    print nltk.tokenwrap(compress(w) for w in english_udhr[:75])\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "regexp = r'^[AEIOUaeiou]+|[AEIOUaeiou]+$|[^AEIOUaeiou]'\n",
    "def compress(word):\n",
    "    pieces = re.findall(regexp, word)\n",
    "    return ''.join(pieces)\n",
    "\n",
    "english_udhr = nltk.corpus.udhr.words('English-Latin1')\n",
    "print nltk.tokenwrap(compress(w) for w in english_udhr[:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package toolbox to\n",
      "[nltk_data]     /Users/kondurharshith/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/toolbox.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('toolbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   e   i   o   u \n",
      "k 418 148  94 420 173 \n",
      "p  83  31 105  34  51 \n",
      "r 187  63  84  89  79 \n",
      "s   0   0 100   2   1 \n",
      "t  47   8   0 148  37 \n",
      "v  93  27 105  48  49 \n"
     ]
    }
   ],
   "source": [
    "rotokas_words = nltk.corpus.toolbox.words('rotokas.dic')\n",
    "cvs = [cv for w in rotokas_words for cv in re.findall(r'[ptksvr][aeiou]', w)]\n",
    "cfd = nltk.ConditionalFreqDist(cvs)\n",
    "cfd.tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kasuari']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_word_pairs = [(cv, w) for w in rotokas_words\n",
    "                          for cv in re.findall(r'[ptksvr][aeiou]', w)]\n",
    "cv_index = nltk.Index(cv_word_pairs)\n",
    "cv_index['su']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> def stem(word):\n",
    "    for suffix in ['ing', 'ly', 'ed', 'ious', 'ies', 'ive', 'es', 's', 'ment']:\n",
    "         if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed and other activities; water and other liquids; tomb and other\n",
      "landmarks; Statues and other monuments; pearls and other jewels;\n",
      "charts and other items; roads and other features; figures and other\n",
      "objects; military and other areas; demands and other factors;\n",
      "abstracts and other compilations; iron and other metals\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "hobbies_learned = nltk.Text(brown.words(categories=['hobbies', 'learned']))\n",
    "hobbies_learned.findall(r\"<\\w*> <and> <other> <\\w*s>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-116-3d563fe732f4>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-116-3d563fe732f4>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    lancaster = nltk.LancasterStemmer()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "   lancaster = nltk.LancasterStemmer()\n",
    "    [porter.stem(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-640eb5622d06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwnl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mwnl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tokens' is not defined"
     ]
    }
   ],
   "source": [
    "wnl = nltk.WordNetLemmatizer()\n",
    "[wnl.lemmatize(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.250994070456922"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.corpus.brown.words()) / len(nltk.corpus.brown.sents())\n",
    "20.250994070456922"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/kondurharshith/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In the wild events which were to follow this girl had no\\n'\n",
      " 'part at all; he never saw her again until all his tale was over.',\n",
      " 'And yet, in some indescribable way, she kept recurring like a\\n'\n",
      " 'motive in music through all his mad adventures afterwards, and the\\n'\n",
      " 'glory of her strange hair ran like a red thread through those dark\\n'\n",
      " 'and ill-drawn tapestries of the night.',\n",
      " 'For what followed was so\\nimprobable, that it might well have been a dream.',\n",
      " 'When Syme went out into the starlit street, he found it for the\\n'\n",
      " 'moment empty.',\n",
      " 'Then he realised (in some odd way) that the silence\\n'\n",
      " 'was rather a living silence than a dead one.',\n",
      " 'Directly outside the\\n'\n",
      " 'door stood a street lamp, whose gleam gilded the leaves of the tree\\n'\n",
      " 'that bent out over the fence behind him.',\n",
      " 'About a foot from the\\n'\n",
      " 'lamp-post stood a figure almost as rigid and motionless as the\\n'\n",
      " 'lamp-post itself.',\n",
      " 'The tall hat and long frock coat were black; the\\n'\n",
      " 'face, in an abrupt shadow, was almost as dark.',\n",
      " 'Only a fringe of\\n'\n",
      " 'fiery hair against the light, and also something aggressive in the\\n'\n",
      " 'attitude, proclaimed that it was the poet Gregory.',\n",
      " 'He had something\\n'\n",
      " 'of the look of a masked bravo waiting sword in hand for his foe.']\n"
     ]
    }
   ],
   "source": [
    "sent_tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "text = nltk.corpus.gutenberg.raw('chesterton-thursday.txt')\n",
    "sents = sent_tokenizer.tokenize(text)\n",
    "pprint.pprint(sents[171:181])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package genesis to\n",
      "[nltk_data]     /Users/kondurharshith/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/genesis.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('genesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_file = open('output.txt', 'w')\n",
    "words = set(nltk.corpus.genesis.words('english-kjv.txt'))\n",
    "for word in sorted(words):\n",
    "     output_file.write(word + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aiuio', 'eaiou', 'eouio', 'euoia', 'oauaio', 'uiieioa']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['attribution', 'confabulation', 'elocution',\n",
    "          'sequoia', 'tenacious', 'unidirectional']\n",
    "vsequences = set()\n",
    "for word in words:\n",
    "    vowels = []\n",
    "    for char in word:\n",
    "         if char in 'aeiou':\n",
    "            vowels.append(char)     \n",
    "    vsequences.add(''.join(vowels))\n",
    "sorted(vsequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'defaultdict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-78a3f6e8a759>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFreqDist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mv1000\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'UNK'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mv1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'defaultdict' is not defined"
     ]
    }
   ],
   "source": [
    "alice = nltk.corpus.gutenberg.words('carroll-alice.txt')\n",
    "vocab = nltk.FreqDist(alice)\n",
    "v1000 = [word for (word, _) in vocab.most_common(1000)]\n",
    "mapping = defaultdict(lambda: 'UNK')\n",
    "for v in v1000:\n",
    "    mapping[v] = v\n",
    "    \n",
    "alice2 = [mapping[v] for v in alice]\n",
    "alice2[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alice2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-52591c3d5544>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malice2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'alice2' is not defined"
     ]
    }
   ],
   "source": [
    "len(set(alice2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/kondurharshith/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30654"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "counts = defaultdict(int)\n",
    "from nltk.corpus import brown\n",
    "for (word, tag) in brown.tagged_words(categories='news', tagset='universal'):\n",
    "    counts[tag] += 1\n",
    "    \n",
    "counts['NOUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " 'ADJ',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'CONJ',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'NUM',\n",
       " 'PRON',\n",
       " 'PRT',\n",
       " 'VERB',\n",
       " 'X']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NOUN', 30654),\n",
       " ('VERB', 14399),\n",
       " ('ADP', 12355),\n",
       " ('.', 11928),\n",
       " ('DET', 11389),\n",
       " ('ADJ', 6706),\n",
       " ('ADV', 3349),\n",
       " ('CONJ', 2717),\n",
       " ('PRON', 2535),\n",
       " ('PRT', 2264),\n",
       " ('NUM', 2166),\n",
       " ('X', 92)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "sorted(counts.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOUN',\n",
       " 'VERB',\n",
       " 'ADP',\n",
       " '.',\n",
       " 'DET',\n",
       " 'ADJ',\n",
       " 'ADV',\n",
       " 'CONJ',\n",
       " 'PRON',\n",
       " 'PRT',\n",
       " 'NUM',\n",
       " 'X']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t for t, c in sorted(counts.items(), key=itemgetter(1), reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8336"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair = ('NP', 8336)\n",
    "pair[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8336"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemgetter(1)(pair)\n",
    "8336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/kondurharshith/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['abactinally',\n",
       " 'abandonedly',\n",
       " 'abasedly',\n",
       " 'abashedly',\n",
       " 'abashlessly',\n",
       " 'abbreviately',\n",
       " 'abdominally',\n",
       " 'abhorrently',\n",
       " 'abidingly',\n",
       " 'abiogenetically',\n",
       " 'abiologically',\n",
       " 'abjectly',\n",
       " 'ableptically',\n",
       " 'ably',\n",
       " 'abnormally',\n",
       " 'abominably',\n",
       " 'aborally',\n",
       " 'aboriginally',\n",
       " 'abortively',\n",
       " 'aboundingly',\n",
       " 'abridgedly',\n",
       " 'abruptedly',\n",
       " 'abruptly',\n",
       " 'abscondedly',\n",
       " 'absently',\n",
       " 'absentmindedly',\n",
       " 'absolutely',\n",
       " 'absolutistically',\n",
       " 'absorbedly',\n",
       " 'absorbingly',\n",
       " 'absorptively',\n",
       " 'abstemiously',\n",
       " 'abstinently',\n",
       " 'abstractedly',\n",
       " 'abstractively',\n",
       " 'abstractly',\n",
       " 'abstrusely',\n",
       " 'absurdly',\n",
       " 'abundantly',\n",
       " 'abusedly',\n",
       " 'abusefully',\n",
       " 'abusively',\n",
       " 'abysmally',\n",
       " 'academically',\n",
       " 'acceleratedly',\n",
       " 'accentually',\n",
       " 'acceptably',\n",
       " 'acceptedly',\n",
       " 'accessarily',\n",
       " 'accessibly',\n",
       " 'accessively',\n",
       " 'accessorily',\n",
       " 'accidentally',\n",
       " 'accidently',\n",
       " 'accommodately',\n",
       " 'accommodatingly',\n",
       " 'accordantly',\n",
       " 'accordingly',\n",
       " 'accountably',\n",
       " 'accumulatively',\n",
       " 'accurately',\n",
       " 'accursedly',\n",
       " 'accusably',\n",
       " 'accusatively',\n",
       " 'accusatorially',\n",
       " 'accusingly',\n",
       " 'accustomedly',\n",
       " 'acervately',\n",
       " 'acetometrically',\n",
       " 'achingly',\n",
       " 'achromatically',\n",
       " 'acicularly',\n",
       " 'acidimetrically',\n",
       " 'acidly',\n",
       " 'acknowledgedly',\n",
       " 'acoustically',\n",
       " 'acquiescently',\n",
       " 'acquiescingly',\n",
       " 'acquisitively',\n",
       " 'acridly',\n",
       " 'acrimoniously',\n",
       " 'acrobatically',\n",
       " 'acrocephaly',\n",
       " 'acrogenously',\n",
       " 'acrologically',\n",
       " 'acromegaly',\n",
       " 'acronically',\n",
       " 'acropetally',\n",
       " 'acrostically',\n",
       " 'actinally',\n",
       " 'actinically',\n",
       " 'actinoelectrically',\n",
       " 'actionably',\n",
       " 'actively',\n",
       " 'actually',\n",
       " 'actuarially',\n",
       " 'acutely',\n",
       " 'Adamically',\n",
       " 'adaptationally',\n",
       " 'adaptively',\n",
       " 'addedly',\n",
       " 'additionally',\n",
       " 'additively',\n",
       " 'addleheadedly',\n",
       " 'adequately',\n",
       " 'adherently',\n",
       " 'adhesively',\n",
       " 'adiabatically',\n",
       " 'adjacently',\n",
       " 'adjectivally',\n",
       " 'adjectively',\n",
       " 'adjoinedly',\n",
       " 'adjunctively',\n",
       " 'adjunctly',\n",
       " 'adjustably',\n",
       " 'administratively',\n",
       " 'admirably',\n",
       " 'admiredly',\n",
       " 'admiringly',\n",
       " 'admissibly',\n",
       " 'admittedly',\n",
       " 'admonishingly',\n",
       " 'admonitively',\n",
       " 'admonitorily',\n",
       " 'adnominally',\n",
       " 'adolescently',\n",
       " 'adoptedly',\n",
       " 'adoptively',\n",
       " 'adorably',\n",
       " 'adorally',\n",
       " 'adoringly',\n",
       " 'adorningly',\n",
       " 'adradially',\n",
       " 'adroitly',\n",
       " 'adscititiously',\n",
       " 'adulterately',\n",
       " 'adulterously',\n",
       " 'adumbratively',\n",
       " 'advancingly',\n",
       " 'advantageously',\n",
       " 'adventitiously',\n",
       " 'adventuresomely',\n",
       " 'adventurously',\n",
       " 'adverbially',\n",
       " 'adversatively',\n",
       " 'adversely',\n",
       " 'advertently',\n",
       " 'advisably',\n",
       " 'advisedly',\n",
       " 'advisorily',\n",
       " 'aerially',\n",
       " 'aerobically',\n",
       " 'aerobiologically',\n",
       " 'aerobiotically',\n",
       " 'aerogenically',\n",
       " 'aeronautically',\n",
       " 'aerophilately',\n",
       " 'aeroscopically',\n",
       " 'aesthetically',\n",
       " 'aetiotropically',\n",
       " 'affably',\n",
       " 'affectedly',\n",
       " 'affectingly',\n",
       " 'affectionally',\n",
       " 'affectionately',\n",
       " 'affectively',\n",
       " 'affinely',\n",
       " 'affinitatively',\n",
       " 'affirmably',\n",
       " 'affirmatively',\n",
       " 'affirmingly',\n",
       " 'afflictingly',\n",
       " 'afflictively',\n",
       " 'affluently',\n",
       " 'affrightedly',\n",
       " 'affrightfully',\n",
       " 'affrightingly',\n",
       " 'affrontedly',\n",
       " 'affrontingly',\n",
       " 'agamically',\n",
       " 'agamogenetically',\n",
       " 'agedly',\n",
       " 'aggravatingly',\n",
       " 'aggregately',\n",
       " 'aggressively',\n",
       " 'aggrievedly',\n",
       " 'agilely',\n",
       " 'agitatedly',\n",
       " 'agnatically',\n",
       " 'agnostically',\n",
       " 'agonistically',\n",
       " 'agonizedly',\n",
       " 'agonizingly',\n",
       " 'agrarianly',\n",
       " 'agreeably',\n",
       " 'agreeingly',\n",
       " 'agriculturally',\n",
       " 'agrobiologically',\n",
       " 'agrogeologically',\n",
       " 'agrologically',\n",
       " 'aguishly',\n",
       " 'aimfully',\n",
       " 'aimlessly',\n",
       " 'airily',\n",
       " 'airtightly',\n",
       " 'alarmedly',\n",
       " 'alarmingly',\n",
       " 'alchemically',\n",
       " 'alcoholically',\n",
       " 'aldermanly',\n",
       " 'alertly',\n",
       " 'algebraically',\n",
       " 'algometrically',\n",
       " 'alimentally',\n",
       " 'alimentatively',\n",
       " 'alkalimetrically',\n",
       " 'allegedly',\n",
       " 'allegorically',\n",
       " 'allenarly',\n",
       " 'alleviatingly',\n",
       " 'alliably',\n",
       " 'allicholly',\n",
       " 'alliteratively',\n",
       " 'allochirally',\n",
       " 'allogenically',\n",
       " 'allopathetically',\n",
       " 'allopathically',\n",
       " 'allopatrically',\n",
       " 'allothigenetically',\n",
       " 'allotropically',\n",
       " 'allowably',\n",
       " 'allowedly',\n",
       " 'alluringly',\n",
       " 'allusively',\n",
       " 'Ally',\n",
       " 'ally',\n",
       " 'almightily',\n",
       " 'alodially',\n",
       " 'alogically',\n",
       " 'aloofly',\n",
       " 'alphabetically',\n",
       " 'alpinely',\n",
       " 'alterably',\n",
       " 'alternately',\n",
       " 'alternatingly',\n",
       " 'alternatively',\n",
       " 'altimetrically',\n",
       " 'altruistically',\n",
       " 'aly',\n",
       " 'amateurishly',\n",
       " 'amatively',\n",
       " 'amatorially',\n",
       " 'amazedly',\n",
       " 'amazingly',\n",
       " 'ambagiously',\n",
       " 'ambassadorially',\n",
       " 'ambidextrously',\n",
       " 'ambiguously',\n",
       " 'ambilateralaterally',\n",
       " 'ambitionlessly',\n",
       " 'ambitiously',\n",
       " 'amblingly',\n",
       " 'ambrosially',\n",
       " 'amenably',\n",
       " 'Americanly',\n",
       " 'ametaboly',\n",
       " 'amethodically',\n",
       " 'amiably',\n",
       " 'amicably',\n",
       " 'amitotically',\n",
       " 'amorously',\n",
       " 'amorphously',\n",
       " 'amphibiously',\n",
       " 'amphibologically',\n",
       " 'amphiboly',\n",
       " 'amphigenously',\n",
       " 'amphimictically',\n",
       " 'amphistyly',\n",
       " 'amphitheatrically',\n",
       " 'amply',\n",
       " 'amusedly',\n",
       " 'amusingly',\n",
       " 'amusively',\n",
       " 'Anabaptistically',\n",
       " 'anacamptically',\n",
       " 'anachronically',\n",
       " 'anachronistically',\n",
       " 'anachronously',\n",
       " 'anacoluthically',\n",
       " 'Anacreontically',\n",
       " 'anacrustically',\n",
       " 'anaerobically',\n",
       " 'anaerobiotically',\n",
       " 'anaesthetically',\n",
       " 'anagogically',\n",
       " 'anagrammatically',\n",
       " 'anally',\n",
       " 'analogically',\n",
       " 'analogously',\n",
       " 'analytically',\n",
       " 'anamnestically',\n",
       " 'anapaestically',\n",
       " 'anarchically',\n",
       " 'anarthrously',\n",
       " 'anathematically',\n",
       " 'Anatoly',\n",
       " 'anatomically',\n",
       " 'ancestorially',\n",
       " 'ancestrally',\n",
       " 'anciently',\n",
       " 'anecdotically',\n",
       " 'anemographically',\n",
       " 'anemometrically',\n",
       " 'anemometrographically',\n",
       " 'anemophily',\n",
       " 'anencephaly',\n",
       " 'anerly',\n",
       " 'anesthetically',\n",
       " 'aneurismally',\n",
       " 'aneurysmally',\n",
       " 'angelically',\n",
       " 'angerly',\n",
       " 'angiomegaly',\n",
       " 'Anglicanly',\n",
       " 'angrily',\n",
       " 'anguishously',\n",
       " 'angularly',\n",
       " 'angulately',\n",
       " 'animally',\n",
       " 'animatedly',\n",
       " 'animately',\n",
       " 'animatingly',\n",
       " 'anisocotyly',\n",
       " 'anisophylly',\n",
       " 'anisotropically',\n",
       " 'anniversarily',\n",
       " 'annoyingly',\n",
       " 'annually',\n",
       " 'annularly',\n",
       " 'anodically',\n",
       " 'anomalistically',\n",
       " 'anomalously',\n",
       " 'anomaly',\n",
       " 'anonymously',\n",
       " 'anorthographically',\n",
       " 'answerably',\n",
       " 'answeringly',\n",
       " 'answerlessly',\n",
       " 'antagonistically',\n",
       " 'antarctically',\n",
       " 'antecedaneously',\n",
       " 'antecedently',\n",
       " 'antediluvially',\n",
       " 'anteriorly',\n",
       " 'anterolaterally',\n",
       " 'anteroposteriorly',\n",
       " 'anteroventrally',\n",
       " 'anthologically',\n",
       " 'anthropologically',\n",
       " 'anthropometrically',\n",
       " 'anthropomorphically',\n",
       " 'anthropomorphologically',\n",
       " 'anthropomorphously',\n",
       " 'anthropopathically',\n",
       " 'anthropophagously',\n",
       " 'antichristianly',\n",
       " 'antichronically',\n",
       " 'anticipatively',\n",
       " 'anticipatorily',\n",
       " 'anticly',\n",
       " 'anticonstitutionally',\n",
       " 'anticyclonically',\n",
       " 'antidotally',\n",
       " 'antidotically',\n",
       " 'antidromically',\n",
       " 'antimonarchically',\n",
       " 'antimonopoly',\n",
       " 'antipathetically',\n",
       " 'antiperistatically',\n",
       " 'antiphonally',\n",
       " 'antiphonically',\n",
       " 'antiphrastically',\n",
       " 'antiquarianly',\n",
       " 'antiquely',\n",
       " 'antirachitically',\n",
       " 'antiseptically',\n",
       " 'antisocialistically',\n",
       " 'antistrophically',\n",
       " 'antitheistically',\n",
       " 'antithetically',\n",
       " 'antitypically',\n",
       " 'antonomastically',\n",
       " 'antrorsely',\n",
       " 'anxiously',\n",
       " 'aoristically',\n",
       " 'apagogically',\n",
       " 'apathetically',\n",
       " 'aperiodically',\n",
       " 'apertly',\n",
       " 'apetaly',\n",
       " 'apheliotropically',\n",
       " 'aphetically',\n",
       " 'aphoristically',\n",
       " 'aphylly',\n",
       " 'apically',\n",
       " 'apishly',\n",
       " 'aplanatically',\n",
       " 'apocalyptically',\n",
       " 'apocryphally',\n",
       " 'apodictically',\n",
       " 'apogamically',\n",
       " 'apogamously',\n",
       " 'apogeotropically',\n",
       " 'apologetically',\n",
       " 'apometaboly',\n",
       " 'apoplectically',\n",
       " 'aposematically',\n",
       " 'apostatically',\n",
       " 'apostolically',\n",
       " 'apothegmatically',\n",
       " 'appallingly',\n",
       " 'apparently',\n",
       " 'appealingly',\n",
       " 'appeasably',\n",
       " 'appeasingly',\n",
       " 'appellatively',\n",
       " 'apperceptively',\n",
       " 'appetently',\n",
       " 'appetizingly',\n",
       " 'applaudably',\n",
       " 'applaudingly',\n",
       " 'applausively',\n",
       " 'appliably',\n",
       " 'applicably',\n",
       " 'applicatively',\n",
       " 'applicatorily',\n",
       " 'appliedly',\n",
       " 'apply',\n",
       " 'applyingly',\n",
       " 'appositely',\n",
       " 'appositionally',\n",
       " 'appositively',\n",
       " 'appraisingly',\n",
       " 'appreciably',\n",
       " 'appreciatingly',\n",
       " 'appreciatively',\n",
       " 'appreciatorily',\n",
       " 'apprehendingly',\n",
       " 'apprehensibly',\n",
       " 'apprehensively',\n",
       " 'appropriately',\n",
       " 'approvedly',\n",
       " 'approvingly',\n",
       " 'approximately',\n",
       " 'approximatively',\n",
       " 'appulsively',\n",
       " 'apsidally',\n",
       " 'aptitudinally',\n",
       " 'aptly',\n",
       " 'aquatically',\n",
       " 'aqueously',\n",
       " 'arabesquely',\n",
       " 'arbitrarily',\n",
       " 'arboreally',\n",
       " 'arborescently',\n",
       " 'Arcadianly',\n",
       " 'archaeologically',\n",
       " 'archaically',\n",
       " 'archetypally',\n",
       " 'archetypically',\n",
       " 'archiepiscopally',\n",
       " 'architectonically',\n",
       " 'architecturally',\n",
       " 'archly',\n",
       " 'arctically',\n",
       " 'arcuately',\n",
       " 'ardently',\n",
       " 'arduously',\n",
       " 'areographically',\n",
       " 'areologically',\n",
       " 'argentometrically',\n",
       " 'argumentatively',\n",
       " 'argutely',\n",
       " 'aridly',\n",
       " 'arightly',\n",
       " 'aristocratically',\n",
       " 'arithmetically',\n",
       " 'aromatically',\n",
       " 'arrantly',\n",
       " 'arrestingly',\n",
       " 'arrhythmically',\n",
       " 'arrogantly',\n",
       " 'arrogatingly',\n",
       " 'arterially',\n",
       " 'artfully',\n",
       " 'articularly',\n",
       " 'articulately',\n",
       " 'artificially',\n",
       " 'artistically',\n",
       " 'artlessly',\n",
       " 'ascendingly',\n",
       " 'ascertainably',\n",
       " 'ascetically',\n",
       " 'aseptically',\n",
       " 'asexually',\n",
       " 'ashamedly',\n",
       " 'ashily',\n",
       " 'Asiatically',\n",
       " 'asininely',\n",
       " 'askingly',\n",
       " 'asperously',\n",
       " 'aspersively',\n",
       " 'aspiringly',\n",
       " 'assembly',\n",
       " 'assentatorily',\n",
       " 'assentingly',\n",
       " 'assertively',\n",
       " 'assertorially',\n",
       " 'assertorically',\n",
       " 'assertorily',\n",
       " 'assessably',\n",
       " 'asseveratingly',\n",
       " 'asseveratively',\n",
       " 'assidually',\n",
       " 'assiduously',\n",
       " 'assignably',\n",
       " 'assishly',\n",
       " 'associatively',\n",
       " 'assumably',\n",
       " 'assumedly',\n",
       " 'assumingly',\n",
       " 'assumptively',\n",
       " 'assuredly',\n",
       " 'assuringly',\n",
       " 'astatically',\n",
       " 'astely',\n",
       " 'asthmatically',\n",
       " 'astigmatically',\n",
       " 'astonishedly',\n",
       " 'astonishingly',\n",
       " 'astoundingly',\n",
       " 'astrally',\n",
       " 'astrictively',\n",
       " 'astringently',\n",
       " 'astrologically',\n",
       " 'astronomically',\n",
       " 'astuciously',\n",
       " 'astutely',\n",
       " 'asymmetrically',\n",
       " 'asymptotically',\n",
       " 'asyndetically',\n",
       " 'atavistically',\n",
       " 'atheistically',\n",
       " 'Athenianly',\n",
       " 'atheologically',\n",
       " 'athletically',\n",
       " 'atmospherically',\n",
       " 'atomically',\n",
       " 'atomistically',\n",
       " 'atonally',\n",
       " 'atoningly',\n",
       " 'atrociously',\n",
       " 'attachedly',\n",
       " 'attemperately',\n",
       " 'attendantly',\n",
       " 'attendingly',\n",
       " 'attentively',\n",
       " 'attently',\n",
       " 'attractingly',\n",
       " 'attractionally',\n",
       " 'attractively',\n",
       " 'attributively',\n",
       " 'attunely',\n",
       " 'atypically',\n",
       " 'audaciously',\n",
       " 'audibly',\n",
       " 'auditorially',\n",
       " 'auditorily',\n",
       " 'augmentatively',\n",
       " 'augmentedly',\n",
       " 'augustly',\n",
       " 'auntly',\n",
       " 'aurally',\n",
       " 'aureately',\n",
       " 'aureously',\n",
       " 'auricularly',\n",
       " 'auriculately',\n",
       " 'aurorally',\n",
       " 'auspiciously',\n",
       " 'austerely',\n",
       " 'auteciously',\n",
       " 'autecologically',\n",
       " 'authentically',\n",
       " 'authenticly',\n",
       " 'authorially',\n",
       " 'authoritatively',\n",
       " 'authorly',\n",
       " 'autobiographically',\n",
       " 'autocatalytically',\n",
       " 'autocephaly',\n",
       " 'autochthonously',\n",
       " 'autocratically',\n",
       " 'autoeciously',\n",
       " 'autoerotically',\n",
       " 'autogenetically',\n",
       " 'autogenously',\n",
       " 'autographically',\n",
       " 'automatically',\n",
       " 'automorphically',\n",
       " 'autonomically',\n",
       " 'autonomously',\n",
       " 'autophytically',\n",
       " 'autoptically',\n",
       " 'autoschediastically',\n",
       " 'autostyly',\n",
       " 'autosymbolically',\n",
       " 'autotropically',\n",
       " 'autumnally',\n",
       " 'auxetically',\n",
       " 'auxiliarly',\n",
       " 'auxinically',\n",
       " 'availably',\n",
       " 'availingly',\n",
       " 'avariciously',\n",
       " 'avengingly',\n",
       " 'averagely',\n",
       " 'aversely',\n",
       " 'avertedly',\n",
       " 'avidiously',\n",
       " 'avidly',\n",
       " 'avoidably',\n",
       " 'avowably',\n",
       " 'avowedly',\n",
       " 'awakeningly',\n",
       " 'awesomely',\n",
       " 'awfully',\n",
       " 'awkwardly',\n",
       " 'axially',\n",
       " 'axiologically',\n",
       " 'axiomatically',\n",
       " 'azimuthally',\n",
       " 'babblingly',\n",
       " 'babblishly',\n",
       " 'babbly',\n",
       " 'babishly',\n",
       " 'babyishly',\n",
       " 'bacchanalianly',\n",
       " 'bachelorly',\n",
       " 'backbitingly',\n",
       " 'backhandedly',\n",
       " 'backwardly',\n",
       " 'bacterially',\n",
       " 'bacteriologically',\n",
       " 'bacterioscopically',\n",
       " 'baddishly',\n",
       " 'badgeringly',\n",
       " 'badgerly',\n",
       " 'badly',\n",
       " 'bafflingly',\n",
       " 'baggily',\n",
       " 'bairnly',\n",
       " 'bakerly',\n",
       " 'bakingly',\n",
       " 'baldly',\n",
       " 'balefully',\n",
       " 'balkingly',\n",
       " 'ballistically',\n",
       " 'bally',\n",
       " 'balmily',\n",
       " 'balsamically',\n",
       " 'banally',\n",
       " 'bandlessly',\n",
       " 'banefully',\n",
       " 'bankruptly',\n",
       " 'banteringly',\n",
       " 'baptismally',\n",
       " 'barbarically',\n",
       " 'barbarously',\n",
       " 'bardily',\n",
       " 'barefacedly',\n",
       " 'barely',\n",
       " 'barfly',\n",
       " 'barkingly',\n",
       " 'barometrically',\n",
       " 'barratrously',\n",
       " 'barrenly',\n",
       " 'barruly',\n",
       " 'basally',\n",
       " 'baselessly',\n",
       " 'basely',\n",
       " 'bashfully',\n",
       " 'basically',\n",
       " 'bastardly',\n",
       " 'bathymetrically',\n",
       " 'bawdily',\n",
       " 'bayardly',\n",
       " 'beadily',\n",
       " 'beamily',\n",
       " 'beamingly',\n",
       " 'bearably',\n",
       " 'bearishly',\n",
       " 'beastily',\n",
       " 'beastlily',\n",
       " 'beastly',\n",
       " 'beatifically',\n",
       " 'beauteously',\n",
       " 'beautifully',\n",
       " 'beckoningly',\n",
       " 'becomingly',\n",
       " 'bedazzlingly',\n",
       " 'beefily',\n",
       " 'beerily',\n",
       " 'beerishly',\n",
       " 'befittingly',\n",
       " 'beggarly',\n",
       " 'beggingly',\n",
       " 'begrudgingly',\n",
       " 'beguilingly',\n",
       " 'behavioristically',\n",
       " 'behoovefully',\n",
       " 'behoovingly',\n",
       " 'beknottedly',\n",
       " 'belatedly',\n",
       " 'believingly',\n",
       " 'bellicosely',\n",
       " 'belligerently',\n",
       " 'belly',\n",
       " 'bely',\n",
       " 'belyingly',\n",
       " 'bemoaningly',\n",
       " 'bemusedly',\n",
       " 'bendingly',\n",
       " 'benedictively',\n",
       " 'beneficently',\n",
       " 'beneficially',\n",
       " 'benevolently',\n",
       " 'benignantly',\n",
       " 'benignly',\n",
       " 'benumbingly',\n",
       " 'beseechingly',\n",
       " 'beseemingly',\n",
       " 'beseemly',\n",
       " 'besiegingly',\n",
       " 'besottedly',\n",
       " 'besottingly',\n",
       " 'bestially',\n",
       " 'besully',\n",
       " 'betterly',\n",
       " 'Beverly',\n",
       " 'bewailingly',\n",
       " 'bewilderedly',\n",
       " 'bewilderingly',\n",
       " 'bewitchingly',\n",
       " 'bewrayingly',\n",
       " 'biannually',\n",
       " 'biaxially',\n",
       " 'Biblically',\n",
       " 'bibliographically',\n",
       " 'bibliophily',\n",
       " 'bibliopolically',\n",
       " 'bibliopoly',\n",
       " 'bibulously',\n",
       " 'biconically',\n",
       " 'biddably',\n",
       " 'bienly',\n",
       " 'biennially',\n",
       " 'bifariously',\n",
       " 'bifidly',\n",
       " 'bifilarly',\n",
       " 'bifurcately',\n",
       " 'bigamously',\n",
       " 'bigotedly',\n",
       " 'bihourly',\n",
       " 'bilaterally',\n",
       " 'bilingually',\n",
       " 'biliously',\n",
       " 'billiardly',\n",
       " 'Billy',\n",
       " 'billy',\n",
       " 'bimanually',\n",
       " 'bimonthly',\n",
       " 'binately',\n",
       " 'bindingly',\n",
       " 'binocularly',\n",
       " 'binomially',\n",
       " 'biochemically',\n",
       " 'bioecologically',\n",
       " 'biogenetically',\n",
       " 'biogeographically',\n",
       " 'biographically',\n",
       " 'biologically',\n",
       " 'biometrically',\n",
       " 'bionomically',\n",
       " 'bipartitely',\n",
       " 'bipinnately',\n",
       " 'biquarterly',\n",
       " 'bisectionally',\n",
       " 'biserially',\n",
       " 'biseriately',\n",
       " 'bisexually',\n",
       " 'bisymmetrically',\n",
       " 'biternately',\n",
       " 'bitingly',\n",
       " 'bitterly',\n",
       " 'biweekly',\n",
       " 'biyearly',\n",
       " 'bizarrely',\n",
       " 'blackbelly',\n",
       " 'blackguardly',\n",
       " 'blackishly',\n",
       " 'blackly',\n",
       " 'blamably',\n",
       " 'blamefully',\n",
       " 'blamelessly',\n",
       " 'blamingly',\n",
       " 'blanchingly',\n",
       " 'blandishingly',\n",
       " 'blandly',\n",
       " 'blankly',\n",
       " 'blasphemously',\n",
       " 'blatantly',\n",
       " 'blately',\n",
       " 'blazingly',\n",
       " 'bleakly',\n",
       " 'bleatingly',\n",
       " 'blenchingly',\n",
       " 'blessedly',\n",
       " 'blessingly',\n",
       " 'blightingly',\n",
       " 'blindedly',\n",
       " 'blindfoldly',\n",
       " 'blindingly',\n",
       " 'blindly',\n",
       " 'blinkingly',\n",
       " 'blissfully',\n",
       " 'blisteringly',\n",
       " 'blithefully',\n",
       " 'blithely',\n",
       " 'blithesomely',\n",
       " 'blizzardly',\n",
       " 'blockheadedly',\n",
       " 'blockishly',\n",
       " 'blolly',\n",
       " 'bloodily',\n",
       " 'bloodlessly',\n",
       " 'bloodthirstily',\n",
       " 'bloomingly',\n",
       " 'blottesquely',\n",
       " 'blottingly',\n",
       " 'blowfly',\n",
       " 'blubberingly',\n",
       " 'bluely',\n",
       " 'bluffly',\n",
       " 'blunderingly',\n",
       " 'bluntly',\n",
       " 'blushfully',\n",
       " 'blushingly',\n",
       " 'blusteringly',\n",
       " 'blusterously',\n",
       " 'boardly',\n",
       " 'boarishly',\n",
       " 'boastfully',\n",
       " 'boatly',\n",
       " 'bobbishly',\n",
       " 'bobfly',\n",
       " 'bodaciously',\n",
       " 'bodily',\n",
       " 'bodingly',\n",
       " 'boilingly',\n",
       " 'boily',\n",
       " 'boisterously',\n",
       " 'boldly',\n",
       " 'bolly',\n",
       " 'bolographically',\n",
       " 'Bolshevistically',\n",
       " 'bombastically',\n",
       " 'bonairly',\n",
       " 'bonally',\n",
       " 'bonelessly',\n",
       " 'bonnily',\n",
       " 'boobily',\n",
       " 'bookishly',\n",
       " 'booly',\n",
       " 'boomingly',\n",
       " 'boorishly',\n",
       " 'bootlessly',\n",
       " 'boozily',\n",
       " 'boringly',\n",
       " 'botanically',\n",
       " 'botchedly',\n",
       " 'botcherly',\n",
       " 'botchily',\n",
       " 'botfly',\n",
       " 'botryoidally',\n",
       " 'bottomlessly',\n",
       " 'bounceably',\n",
       " 'bouncingly',\n",
       " 'boundedly',\n",
       " 'boundingly',\n",
       " 'boundlessly',\n",
       " 'boundly',\n",
       " 'bounteously',\n",
       " 'bountifully',\n",
       " 'bovinely',\n",
       " 'bowingly',\n",
       " 'bowly',\n",
       " 'boyishly',\n",
       " 'brabblingly',\n",
       " 'brachistocephaly',\n",
       " 'brachycephaly',\n",
       " 'brachydactyly',\n",
       " 'bracingly',\n",
       " 'braggartly',\n",
       " 'braggingly',\n",
       " 'braggishly',\n",
       " 'brainlessly',\n",
       " 'brainsickly',\n",
       " 'brambly',\n",
       " 'brassily',\n",
       " 'bravely',\n",
       " 'brawlingly',\n",
       " 'brawly',\n",
       " 'brawnily',\n",
       " 'brazenfacedly',\n",
       " 'brazenly',\n",
       " 'breakably',\n",
       " 'breathingly',\n",
       " 'breathlessly',\n",
       " 'breezily',\n",
       " 'bremely',\n",
       " 'brickly',\n",
       " 'bridally',\n",
       " 'bridely',\n",
       " 'brieflessly',\n",
       " 'briefly',\n",
       " 'brigandishly',\n",
       " 'brightly',\n",
       " 'brilliantly',\n",
       " 'brimfully',\n",
       " 'brimmingly',\n",
       " 'briskly',\n",
       " 'bristly',\n",
       " 'Britannically',\n",
       " 'Britishly',\n",
       " 'brittlely',\n",
       " 'broadly',\n",
       " 'broilingly',\n",
       " 'brokenheartedly',\n",
       " 'brokenly',\n",
       " 'brolly',\n",
       " 'bromidically',\n",
       " 'bromometrically',\n",
       " 'bronchially',\n",
       " 'broodingly',\n",
       " 'brotherly',\n",
       " 'brownly',\n",
       " 'brusquely',\n",
       " 'brutally',\n",
       " 'brutely',\n",
       " 'brutishly',\n",
       " 'bubblingly',\n",
       " 'bubbly',\n",
       " 'buccally',\n",
       " 'buckishly',\n",
       " 'bucolically',\n",
       " 'buirdly',\n",
       " 'bulkily',\n",
       " 'bullheadedly',\n",
       " 'bullishly',\n",
       " 'bully',\n",
       " 'bumpily',\n",
       " 'bumpingly',\n",
       " 'bumpkinly',\n",
       " 'bumptiously',\n",
       " 'bunchily',\n",
       " 'bungerly',\n",
       " 'bunglingly',\n",
       " 'buoyantly',\n",
       " 'burbly',\n",
       " 'burdensomely',\n",
       " 'bureaucratically',\n",
       " 'burglariously',\n",
       " 'burlesquely',\n",
       " 'burlily',\n",
       " 'burly',\n",
       " 'burningly',\n",
       " 'bushily',\n",
       " 'busily',\n",
       " 'bustlingly',\n",
       " 'butcherly',\n",
       " 'butterfly',\n",
       " 'butyrically',\n",
       " 'buxomly',\n",
       " 'buzzardly',\n",
       " 'buzzingly',\n",
       " 'byously',\n",
       " 'Byronically',\n",
       " 'cabalistically',\n",
       " 'cacophonically',\n",
       " 'cacophonously',\n",
       " ...]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "last_letters = defaultdict(list)\n",
    "words = nltk.corpus.words.words('en')\n",
    "for word in words:\n",
    "    key = word[-2:]\n",
    "    last_letters[key].append(word)\n",
    "    \n",
    "last_letters['ly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blazy',\n",
       " 'bleezy',\n",
       " 'blowzy',\n",
       " 'boozy',\n",
       " 'breezy',\n",
       " 'bronzy',\n",
       " 'buzzy',\n",
       " 'Chazy',\n",
       " 'cozy',\n",
       " 'crazy',\n",
       " 'dazy',\n",
       " 'dizzy',\n",
       " 'dozy',\n",
       " 'enfrenzy',\n",
       " 'fezzy',\n",
       " 'fizzy',\n",
       " 'floozy',\n",
       " 'fozy',\n",
       " 'franzy',\n",
       " 'frenzy',\n",
       " 'friezy',\n",
       " 'frizzy',\n",
       " 'frowzy',\n",
       " 'furzy',\n",
       " 'fuzzy',\n",
       " 'gauzy',\n",
       " 'gazy',\n",
       " 'glazy',\n",
       " 'groszy',\n",
       " 'hazy',\n",
       " 'heezy',\n",
       " 'Izzy',\n",
       " 'jazzy',\n",
       " 'Jozy',\n",
       " 'lawzy',\n",
       " 'lazy',\n",
       " 'mazy',\n",
       " 'mizzy',\n",
       " 'muzzy',\n",
       " 'nizy',\n",
       " 'oozy',\n",
       " 'quartzy',\n",
       " 'quizzy',\n",
       " 'refrenzy',\n",
       " 'ritzy',\n",
       " 'Shortzy',\n",
       " 'sizy',\n",
       " 'sleazy',\n",
       " 'sneezy',\n",
       " 'snoozy',\n",
       " 'squeezy',\n",
       " 'Suzy',\n",
       " 'tanzy',\n",
       " 'tizzy',\n",
       " 'topazy',\n",
       " 'trotcozy',\n",
       " 'twazzy',\n",
       " 'unbreezy',\n",
       " 'unfrizzy',\n",
       " 'wheezy',\n",
       " 'woozy',\n",
       " 'wuzzy',\n",
       " 'yezzy']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_letters['zy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entrail', 'latrine', 'ratline', 'reliant', 'retinal', 'trenail']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anagrams = defaultdict(list)\n",
    "for word in words:\n",
    "    key = ''.join(sorted(word))\n",
    "    anagrams[key].append(word)\n",
    "    \n",
    "anagrams['aeilnrt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entrail', 'latrine', 'ratline', 'reliant', 'retinal', 'trenail']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anagrams = nltk.Index((''.join(sorted(w)), w) for w in words)\n",
    "anagrams['aeilnrt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'NOUN': 5, 'ADJ': 11})"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = defaultdict(lambda: defaultdict(int))\n",
    "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
    "for ((w1, t1), (w2, t2)) in nltk.bigrams(brown_news_tagged): \n",
    "    pos[(t1, w2)][t2] += 1\n",
    "    \n",
    "pos[('DET', 'right')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mortal',\n",
       " 'Against',\n",
       " 'Him',\n",
       " 'There',\n",
       " 'brought',\n",
       " 'King',\n",
       " 'virtue',\n",
       " 'every',\n",
       " 'been',\n",
       " 'thine']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = defaultdict(int)\n",
    "for word in nltk.corpus.gutenberg.words('milton-paradise.txt'):\n",
    "    counts[word] += 1\n",
    "[key for (key, value) in counts.items() if value == 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ideas'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = {'colorless': 'ADJ', 'ideas': 'N', 'sleep': 'V', 'furiously': 'ADV'}\n",
    "pos2 = dict((value, key) for (key, value) in pos.items())\n",
    "pos2['N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['furiously', 'peacefully']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.update({'cats': 'N', 'scratch': 'V', 'peacefully': 'ADV', 'old': 'ADJ'})\n",
    "pos2 = defaultdict(list)\n",
    "for key, value in pos.items():\n",
    "    pos2[value].append(key)\n",
    "pos2['ADV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NN'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "brown_sents = brown.sents(categories='news')\n",
    "tags = [tag for (word, tag) in brown.tagged_words(categories='news')]\n",
    "nltk.FreqDist(tags).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-558c7703a98b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'I do not like green eggs and ham, I do not like them Sam I am!'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdefault_tagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDefaultTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdefault_tagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "raw = 'I do not like green eggs and ham, I do not like them Sam I am!'\n",
    "tokens = word_tokenize(raw)\n",
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "default_tagger.tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'default_tagger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-87a1170c976d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdefault_tagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrown_tagged_sents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'default_tagger' is not defined"
     ]
    }
   ],
   "source": [
    "default_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regexp_tagger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-b6c55785f775>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mregexp_tagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrown_tagged_sents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'regexp_tagger' is not defined"
     ]
    }
   ],
   "source": [
    "regexp_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pylab\n",
    "from pylab import *\n",
    "def performance(cfd, wordlist):\n",
    "    lt = dict((word, cfd[word].max()) for word in wordlist)\n",
    "    baseline_tagger = nltk.UnigramTagger(model=lt, backoff=nltk.DefaultTagger('NN'))\n",
    "    return baseline_tagger.evaluate(brown.tagged_sents(categories='news'))\n",
    "\n",
    "def display():\n",
    "    #import pylab\n",
    "    word_freqs = nltk.FreqDist(brown.words(categories='news')).most_common()\n",
    "    words_by_freq = [w for (w, _) in word_freqs]\n",
    "    cfd = nltk.ConditionalFreqDist(brown.tagged_words(categories='news'))\n",
    "    sizes = 2 ** pylab.arange(15)\n",
    "    perfs = [performance(cfd, words_by_freq[:size]) for size in sizes]\n",
    "    pylab.plot(sizes, perfs, '-bo')\n",
    "    pylab.title('Lookup Tagger Performance with Varying Model Size')\n",
    "    pylab.xlabel('Model Size')\n",
    "    pylab.ylabel('Performance')\n",
    "    pylab.show()\n",
    "    \n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Various', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('apartments', 'NNS'),\n",
       " ('are', 'BER'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('terrace', 'NN'),\n",
       " ('type', 'NN'),\n",
       " (',', ','),\n",
       " ('being', 'BEG'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('ground', 'NN'),\n",
       " ('floor', 'NN'),\n",
       " ('so', 'QL'),\n",
       " ('that', 'CS'),\n",
       " ('entrance', 'NN'),\n",
       " ('is', 'BEZ'),\n",
       " ('direct', 'JJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "brown_sents = brown.sents(categories='news')\n",
    "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)\n",
    "unigram_tagger.tag(brown_sents[2007])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9349006503968017"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4160"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = int(len(brown_tagged_sents) * 0.9)\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8121200039868434"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents = brown_tagged_sents[:size]\n",
    "test_sents = brown_tagged_sents[size:]\n",
    "unigram_tagger = nltk.UnigramTagger(train_sents)\n",
    "unigram_tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Various', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('apartments', 'NNS'),\n",
       " ('are', 'BER'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('terrace', 'NN'),\n",
       " ('type', 'NN'),\n",
       " (',', ','),\n",
       " ('being', 'BEG'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('ground', 'NN'),\n",
       " ('floor', 'NN'),\n",
       " ('so', 'CS'),\n",
       " ('that', 'CS'),\n",
       " ('entrance', 'NN'),\n",
       " ('is', 'BEZ'),\n",
       " ('direct', 'JJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tagger = nltk.BigramTagger(train_sents)\n",
    "bigram_tagger.tag(brown_sents[2007])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "output = open('t2.pkl', 'wb')\n",
    "dump(t2, output, -1)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tagger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-37b0d5bab8d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     is up against in our complex maze of regulatory laws .\"\"\"\n\u001b[1;32m      3\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tagger' is not defined"
     ]
    }
   ],
   "source": [
    "text = \"\"\"The board's action shows what free enterprise\n",
    "    is up against in our complex maze of regulatory laws .\"\"\"\n",
    "tokens = text.split()\n",
    "tagger.tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.from_iter(generator)) or the python sum builtin instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.049297702068029296"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist(\n",
    "           ((x[1], y[1], z[0]), z[1])\n",
    "           for sent in brown_tagged_sents\n",
    "           for x, y, z in nltk.trigrams(sent))\n",
    "ambiguous_contexts = [c for c in cfd.conditions() if len(cfd[c]) > 1]\n",
    "sum(cfd[c].N() for c in ambiguous_contexts) / cfd.N()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
