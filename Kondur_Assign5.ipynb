{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kondur-Assign5",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "y_zb-KGkittm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Assignment 5: IMDB review sample Classification with fast.ai Deep Learning Framework"
      ]
    },
    {
      "metadata": {
        "id": "oGvN9KtGi4T_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 1: (10 points)**\n",
        "\n",
        "Export the sample data set you created in [Classwork 3](https://colab.research.google.com/drive/1be7ksupqRkdjU1fZUAS37F5GiLCkFzkR) with pickle library, name it `imdb-sample.pickle`, and upload it to Google Colab. Then run the following codes."
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "s3rD3HkMbCq-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "cc050bc1-a3ac-4332-fb09-766af1fd4d99"
      },
      "cell_type": "code",
      "source": [
        "from fastai.text import *\n",
        "path = Path('.')\n",
        "with open(\"imdb-sample.pickle\", 'rb') as f:\n",
        "    train, valid = pickle.load(f)\n",
        "    "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-fab4366b385a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"imdb-sample.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'imdb-sample.pickle'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Fq5y-9kCEHdU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dJy9CWMijk9v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You should see the output like this:\n",
        "\n",
        "![](https://github.com/wshuyi/github_pub_img/raw/master/assets/2019-03-26-10-11-10-085256.png)"
      ]
    },
    {
      "metadata": {
        "id": "pD8ua3DMjt2V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 2: (10 points)**\n",
        "\n",
        "Create a TextLMDataBunch instance called `data_lm`, load your train and valid Dataframe into it, and run the following code."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3eb854d800019951627b86b9d0d2ddb1b0690dff",
        "id": "-5Y4DLmIbCsF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_lm = TextLMDataBunch.from_df(path=path, train_df=train , valid_df=valid, text_cols=0, label_cols=1 )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "046c6510e26fe07dcf7d87936a80ffa079a46e4b",
        "id": "e87K11gHbCsP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_lm.show_batch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O2_lfse1pkup",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You should see the output like this:\n",
        "\n",
        "![](https://github.com/wshuyi/github_pub_img/raw/master/assets/2019-03-26-10-14-25-459713.png)"
      ]
    },
    {
      "metadata": {
        "id": "LaqcTDHikUOm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 3: (10 points)**\n",
        "\n",
        "Create a `language_model_learner` named `learn`, use `data_lm` as input data, `AWD_LSTM` as architecture, and choose 0.5 as Dropout rate. Draw the result of learning rate finder."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "04ce1c9b393afde82a2301ac217760a4f559a7c6",
        "id": "Dl21NZpzbCsU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5)\n",
        "learn.lr_find()\n",
        "learn.recorder.plot(skip_end=5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RRFH6xlOmEmz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You should see the output like this:\n",
        "\n",
        "![](https://github.com/wshuyi/github_pub_img/raw/master/assets/2019-03-26-10-17-47-701082.png)"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kYdco7i0lNsW"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 4: (20 points)**\n",
        "\n",
        "Fit one cycle with your language learner (`learn`), unfreeze it and fit another 3 cycles. Save the language learner's encoder as `ft_enc`."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "baafa7bf5fd351f5dca7a5f6cf1f89c84a3281e8",
        "id": "Vr1IdeC0bCsp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))\n",
        "learn.save('fit_head')\n",
        "learn.load('fit_head');\n",
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(3, 1e-3, moms=(0.8,0.7))\n",
        "learn.save('fine_tuned')\n",
        "learn.load('fine_tuned')\n",
        "learn.save_encoder('ft_enc')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Bb_WPtcmGYz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You should see the output like this:\n",
        "\n",
        "![](https://github.com/wshuyi/github_pub_img/raw/master/assets/2019-03-26-10-20-09-953060.png)"
      ]
    },
    {
      "metadata": {
        "id": "MI5j3jWQmLmv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 5: (10 points)**\n",
        "\n",
        "Create a TextClasDataBunch instance called `data_clas`, load your train and valid Dataframe into it, use the vocab from `data_lm.train_ds.vocab`, set batch size as 32, and run the following code."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d8c40e52341b435d6bb828faf6fbee1095262192",
        "id": "sOWsKtK8bCtC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "data_clas = TextClasDataBunch.from_df(path, train_df=train, valid_df=valid, text_cols=0, label_cols=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0105c7ddb6df1dd207c9533dd98804d59a4fcce6",
        "id": "xGRPON5wbCtQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_clas.show_batch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LXrBPvi0njxX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You should see the output like this:\n",
        "\n",
        "![](https://github.com/wshuyi/github_pub_img/raw/master/assets/2019-03-26-10-24-53-893234.png)"
      ]
    },
    {
      "metadata": {
        "id": "BjA_2QH0m6AZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 6: (10 points)**\n",
        "\n",
        "Create a `text_classifier_learner` named `learn`, use `data_clas` as input data, `AWD_LSTM` as architecture, and choose 0.5 as Dropout rate. Note to compare the result with Scikit-learn and textblob later, you need to make sure Precision and Recall are in the metrics list. Load the encoder  (`ft_enc`) you saved just now into `learn`. Draw the result of learning rate finder."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ee96a122db78a62ee1a841ec2b63761d643b11b9",
        "id": "KFi3uvq-bCtH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
        "learn.load_encoder('ft_enc')\n",
        "learn.lr_find()\n",
        "learn.recorder.plot(skip_end=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vqn-pdAXniIw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You should see the output like this:\n",
        "\n",
        "![](https://github.com/wshuyi/github_pub_img/raw/master/assets/2019-03-26-10-27-55-239469.png)"
      ]
    },
    {
      "metadata": {
        "id": "FdAZakubnwx7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 7: (20 points)**\n",
        "\n",
        "Fit one cycle with your text classifier learner (`learn`). Unfreeze the last two layers, and fit 3 cycles. Then unfreeze it totally, and fit another 2 cycles. Show the training result."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b612e63b0a924444712627e3cc2224c2f69bfc7d",
        "id": "jdO8fcfxbCtY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))\n",
        "learn.save('fit_head')\n",
        "learn.load('fit_head');\n",
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(3, 1e-3, moms=(0.8,0.7))\n",
        "learn.save('fine_tuned')\n",
        "learn.load('fine_tuned')\n",
        "learn.save_encoder('result')\n",
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(2, 1e-3, moms=(0.8,0.7))\n",
        "learn.save('fine_tuned')\n",
        "learn.load('fine_tuned')\n",
        "learn.save_encoder('result')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4LOhB6DRoUqU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You should see the output like this:\n",
        "\n",
        "![](https://github.com/wshuyi/github_pub_img/raw/master/assets/2019-03-26-10-31-32-631875.png)"
      ]
    },
    {
      "metadata": {
        "id": "C4A7JMTnobiI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 8: (10 points)**\n",
        "\n",
        "Comparing the result with those from textblob, scikit-learn in Classwork 3, what is your finding? How about comparing with the result from Self-study 7 (the whole IMDB dataset)? Write down your answer and comments."
      ]
    },
    {
      "metadata": {
        "id": "cQypGalko4LQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Your answer here:*\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b59afd22f92c215777af52635ceea9fa76c3b10c",
        "id": "yde4NU-ObCt3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "The result is more accurate than the result from textblob in classwork 3.However,this result has lower precision than the result from IMDB data set, which means the large data set helps us to produce more accurate results."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}